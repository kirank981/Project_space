{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirank981/Project_space/blob/main/project_space.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP5nJnDbJPYO"
      },
      "source": [
        "# Installing dependences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OravxoTjLhVa"
      },
      "source": [
        "Install the necessary packages for PyTorch (torch and torchvision) and Flower (flwr) and pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kpAFZGHjJOOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c149ab1-1b48-4209-a0ed-0a2d6f5d151e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIQeKkPPLUkF"
      },
      "source": [
        "Import everything we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdmn7_KHLVVI",
        "outputId": "34d3ffa4-e445-4e4c-fbc7-1e9b70f35515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 2.0.1+cu118 and Flower 1.4.0\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeFfbJxnLxF7"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6l5c_376GqC"
      },
      "source": [
        "Mounting drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSv4I6ji-3of",
        "outputId": "49a08872-325d-4066-9d63-511a0b2f5c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n4a987x-7kd"
      },
      "source": [
        "Setting the path to the location of the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jQ1t9RTF91ZQ"
      },
      "outputs": [],
      "source": [
        "# Define the path to daily dataset folder\n",
        "daily_dataset_path = Path('/content/drive/MyDrive/Federated learning implementation/dataset/dataset_archive/daily_dataset/daily_dataset')\n",
        "\n",
        "# Define the path to daily dataset folder\n",
        "weather_daily_dataset_path = Path('/content/drive/MyDrive/Federated learning implementation/dataset/dataset_archive/weather_daily_dataset.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ2owcEz6M9K"
      },
      "source": [
        "## Loading daily data\n",
        "(of energy consumption)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QdpP9rwQBqJF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initializing list to store dataframes\n",
        "dfs = []\n",
        "\n",
        "# Loop through the CSV files and reading them into dataframes\n",
        "for i in range(111):\n",
        "    filename = f'block_{i}.csv'\n",
        "    df = pd.read_csv(daily_dataset_path / filename)\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenating all the dataframes into a single dataframe\n",
        "energy_daily_data = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# NRATM\n",
        "# # Group the data by LCLid and create a dictionary of dataframes\n",
        "# grouped_data = dict(tuple(energy_daily_data.groupby('LCLid')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBAsp3Ky51Bn"
      },
      "source": [
        "Loading data using file name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeJMbTTY0YZY",
        "outputId": "0016caa8-bfa1-4f23-e437-541f517b1046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           LCLid         day  energy_median  energy_mean  energy_max  \\\n",
            "0      MAC000002  2012-10-12         0.1385     0.154304       0.886   \n",
            "1      MAC000002  2012-10-13         0.1800     0.230979       0.933   \n",
            "2      MAC000002  2012-10-14         0.1580     0.275479       1.085   \n",
            "3      MAC000002  2012-10-15         0.1310     0.213688       1.164   \n",
            "4      MAC000002  2012-10-16         0.1450     0.203521       0.991   \n",
            "...          ...         ...            ...          ...         ...   \n",
            "25569  MAC005492  2014-02-24         0.1690     0.175042       0.378   \n",
            "25570  MAC005492  2014-02-25         0.1550     0.160792       0.545   \n",
            "25571  MAC005492  2014-02-26         0.1490     0.178542       0.687   \n",
            "25572  MAC005492  2014-02-27         0.1140     0.146167       0.478   \n",
            "25573  MAC005492  2014-02-28         0.0880     0.088000       0.088   \n",
            "\n",
            "       energy_count  energy_std  energy_sum  energy_min  \n",
            "0                46    0.196034       7.098       0.000  \n",
            "1                48    0.192329      11.087       0.076  \n",
            "2                48    0.274647      13.223       0.070  \n",
            "3                48    0.224483      10.257       0.070  \n",
            "4                48    0.184115       9.769       0.087  \n",
            "...             ...         ...         ...         ...  \n",
            "25569            48    0.073174       8.402       0.079  \n",
            "25570            48    0.082118       7.718       0.079  \n",
            "25571            48    0.120820       8.570       0.079  \n",
            "25572            48    0.082616       7.016       0.079  \n",
            "25573             1         NaN       0.088       0.088  \n",
            "\n",
            "[25574 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "# Loading data from a specific CSV file\n",
        "specific_file_data = pd.read_csv(daily_dataset_path / 'block_0.csv')\n",
        "\n",
        "# Displaying data\n",
        "print(specific_file_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0b947PkSfrG"
      },
      "source": [
        "### Loading required data\n",
        "Creating a DataFrame that have only the required data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMsi4uZITUt8",
        "outputId": "01e21f40-f70d-4703-ba1e-d6966602fd88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             LCLid  energy_sum         day\n",
            "0        MAC000002       7.098  2012-10-12\n",
            "1        MAC000002      11.087  2012-10-13\n",
            "2        MAC000002      13.223  2012-10-14\n",
            "3        MAC000002      10.257  2012-10-15\n",
            "4        MAC000002       9.769  2012-10-16\n",
            "...            ...         ...         ...\n",
            "3500520  MAC005567       4.107  2014-02-24\n",
            "3500521  MAC005567       5.762  2014-02-25\n",
            "3500522  MAC005567       5.066  2014-02-26\n",
            "3500523  MAC005567       3.217  2014-02-27\n",
            "3500524  MAC005567       0.183  2014-02-28\n",
            "\n",
            "[3500525 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "selected_column = ['LCLid','energy_sum','day']\n",
        "energy_daily_selected=energy_daily_data[selected_column]\n",
        "print(energy_daily_selected)\n",
        "\n",
        "# Group the data by LCLid and create a dictionary of dataframes\n",
        "grouped_data_selected = dict(tuple(energy_daily_selected.groupby('LCLid')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6b7s1na56YA"
      },
      "source": [
        "Loading data using the 'LCLid'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw5Oqcz9DeWZ",
        "outputId": "e2a72cf5-62e3-4e33-cbf1-ac3a3fc3efaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         LCLid  energy_sum         day\n",
            "0    MAC000002       7.098  2012-10-12\n",
            "1    MAC000002      11.087  2012-10-13\n",
            "2    MAC000002      13.223  2012-10-14\n",
            "3    MAC000002      10.257  2012-10-15\n",
            "4    MAC000002       9.769  2012-10-16\n",
            "..         ...         ...         ...\n",
            "500  MAC000002      12.528  2014-02-24\n",
            "501  MAC000002      11.826  2014-02-25\n",
            "502  MAC000002      12.328  2014-02-26\n",
            "503  MAC000002      20.518  2014-02-27\n",
            "504  MAC000002       1.387  2014-02-28\n",
            "\n",
            "[505 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Now can access each dataframe separately using the LCLid as the key\n",
        "# for \"MAC000002\"(random)\n",
        "mac000002_data = grouped_data_selected['MAC000002']\n",
        "\n",
        "# Display the data for 'MAC000002'\n",
        "print(mac000002_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZumIN7H_Zt-"
      },
      "source": [
        "## Loading daily weather data\n",
        "\n",
        "Creating a 'day' column that stores only the date values from 'time' column\n",
        "(for linking weather dataset 'day' with daily dataset 'day')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch2Azrah7Cuj",
        "outputId": "8b265018-b89b-4690-8ceb-a02407946b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     temperatureMax   temperatureMaxTime  windBearing                 icon  \\\n",
            "0             11.96  2011-11-11 23:00:00          123                  fog   \n",
            "1              8.59  2011-12-11 14:00:00          198    partly-cloudy-day   \n",
            "2             10.33  2011-12-27 02:00:00          225    partly-cloudy-day   \n",
            "3              8.07  2011-12-02 23:00:00          232                 wind   \n",
            "4              8.22  2011-12-24 23:00:00          252  partly-cloudy-night   \n",
            "..              ...                  ...          ...                  ...   \n",
            "877            9.03  2014-01-26 16:00:00          233    partly-cloudy-day   \n",
            "878           10.31  2014-02-27 14:00:00          224    partly-cloudy-day   \n",
            "879           18.97  2014-03-09 14:00:00          172  partly-cloudy-night   \n",
            "880            8.83  2014-02-12 16:00:00          210                 wind   \n",
            "881            9.90  2014-02-15 12:00:00          233                 wind   \n",
            "\n",
            "     dewPoint   temperatureMinTime  cloudCover  windSpeed  pressure  \\\n",
            "0        9.40  2011-11-11 07:00:00        0.79       3.88   1016.08   \n",
            "1        4.49  2011-12-11 01:00:00        0.56       3.94   1007.71   \n",
            "2        5.47  2011-12-27 23:00:00        0.85       3.54   1032.76   \n",
            "3        3.69  2011-12-02 07:00:00        0.32       3.00   1012.12   \n",
            "4        2.79  2011-12-24 07:00:00        0.37       4.46   1028.17   \n",
            "..        ...                  ...         ...        ...       ...   \n",
            "877      2.39  2014-01-26 21:00:00        0.40       4.55   1002.10   \n",
            "878      3.08  2014-02-27 23:00:00        0.32       4.14   1007.02   \n",
            "879      4.30  2014-03-09 07:00:00        0.04       2.78   1022.44   \n",
            "880      1.94  2014-02-12 01:00:00        0.59       7.24    994.27   \n",
            "881      2.95  2014-02-15 23:00:00        0.35       9.96    988.63   \n",
            "\n",
            "    apparentTemperatureMinTime  ...          sunriseTime  temperatureHighTime  \\\n",
            "0          2011-11-11 07:00:00  ...  2011-11-11 07:12:14  2011-11-11 19:00:00   \n",
            "1          2011-12-11 02:00:00  ...  2011-12-11 07:57:02  2011-12-11 14:00:00   \n",
            "2          2011-12-27 22:00:00  ...  2011-12-27 08:07:06  2011-12-27 14:00:00   \n",
            "3          2011-12-02 07:00:00  ...  2011-12-02 07:46:09  2011-12-02 12:00:00   \n",
            "4          2011-12-24 07:00:00  ...  2011-12-24 08:06:15  2011-12-24 15:00:00   \n",
            "..                         ...  ...                  ...                  ...   \n",
            "877        2014-01-26 22:00:00  ...  2014-01-26 07:48:49  2014-01-26 16:00:00   \n",
            "878        2014-02-27 22:00:00  ...  2014-02-27 06:51:45  2014-02-27 14:00:00   \n",
            "879        2014-03-09 07:00:00  ...  2014-03-09 06:29:49  2014-03-09 14:00:00   \n",
            "880        2014-02-12 01:00:00  ...  2014-02-12 07:21:44  2014-02-12 16:00:00   \n",
            "881        2014-02-15 23:00:00  ...  2014-02-15 07:16:06  2014-02-15 12:00:00   \n",
            "\n",
            "             uvIndexTime                                            summary  \\\n",
            "0    2011-11-11 11:00:00                             Foggy until afternoon.   \n",
            "1    2011-12-11 12:00:00                  Partly cloudy throughout the day.   \n",
            "2    2011-12-27 00:00:00                  Mostly cloudy throughout the day.   \n",
            "3    2011-12-02 10:00:00  Partly cloudy throughout the day and breezy ov...   \n",
            "4    2011-12-24 13:00:00                  Mostly cloudy throughout the day.   \n",
            "..                   ...                                                ...   \n",
            "877  2014-01-26 11:00:00                       Mostly cloudy until evening.   \n",
            "878  2014-02-27 12:00:00                       Partly cloudy until evening.   \n",
            "879  2014-03-09 12:00:00                      Partly cloudy in the evening.   \n",
            "880  2014-02-12 10:00:00  Mostly cloudy until evening and breezy through...   \n",
            "881  2014-02-15 10:00:00           Windy and mostly cloudy until afternoon.   \n",
            "\n",
            "      temperatureLowTime  apparentTemperatureMin  apparentTemperatureMaxTime  \\\n",
            "0    2011-11-11 19:00:00                    6.48         2011-11-11 23:00:00   \n",
            "1    2011-12-12 07:00:00                    0.11         2011-12-11 20:00:00   \n",
            "2    2011-12-27 23:00:00                    5.59         2011-12-27 02:00:00   \n",
            "3    2011-12-02 19:00:00                    0.46         2011-12-02 12:00:00   \n",
            "4    2011-12-24 19:00:00                   -0.51         2011-12-24 23:00:00   \n",
            "..                   ...                     ...                         ...   \n",
            "877  2014-01-27 05:00:00                   -1.30         2014-01-26 15:00:00   \n",
            "878  2014-02-28 02:00:00                    1.41         2014-02-27 14:00:00   \n",
            "879  2014-03-10 05:00:00                    7.08         2014-03-09 14:00:00   \n",
            "880  2014-02-13 05:00:00                   -1.20         2014-02-12 16:00:00   \n",
            "881  2014-02-16 07:00:00                    1.77         2014-02-15 12:00:00   \n",
            "\n",
            "     apparentTemperatureLowTime moonPhase mean_temp  \n",
            "0           2011-11-11 19:00:00      0.52    10.405  \n",
            "1           2011-12-12 08:00:00      0.53     5.535  \n",
            "2           2011-12-28 00:00:00      0.10     9.180  \n",
            "3           2011-12-02 19:00:00      0.25     5.315  \n",
            "4           2011-12-24 20:00:00      0.99     5.695  \n",
            "..                          ...       ...       ...  \n",
            "877         2014-01-27 04:00:00      0.84     6.145  \n",
            "878         2014-02-28 02:00:00      0.93     7.120  \n",
            "879         2014-03-10 06:00:00      0.28    13.310  \n",
            "880         2014-02-13 02:00:00      0.42     5.930  \n",
            "881         2014-02-16 07:00:00      0.52     7.640  \n",
            "\n",
            "[882 rows x 33 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load the weather dataset into a DataFrame\n",
        "weather_daily_data = pd.read_csv(weather_daily_dataset_path)\n",
        "\n",
        "# Convert the 'time' column to datetime format\n",
        "weather_daily_data['time'] = pd.to_datetime(weather_daily_data['time'])\n",
        "\n",
        "# Calculate the mean temperature for each day and store it in a new column 'mean_temp'\n",
        "weather_daily_data['mean_temp'] = (weather_daily_data['temperatureMax'] + weather_daily_data['temperatureMin']) / 2\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(weather_daily_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUsgV_WfSTVp"
      },
      "source": [
        "### Loading required data\n",
        "Creating a DataFrame that have only the required data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRn0x1J8RlPl",
        "outputId": "4bac929d-30c9-45b0-fcde-7cf830fcff39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     mean_temp  pressure  humidity  windSpeed       time\n",
            "0       10.405   1016.08      0.95       3.88 2011-11-11\n",
            "1        5.535   1007.71      0.88       3.94 2011-12-11\n",
            "2        9.180   1032.76      0.74       3.54 2011-12-27\n",
            "3        5.315   1012.12      0.87       3.00 2011-12-02\n",
            "4        5.695   1028.17      0.80       4.46 2011-12-24\n",
            "..         ...       ...       ...        ...        ...\n",
            "877      6.145   1002.10      0.79       4.55 2014-01-26\n",
            "878      7.120   1007.02      0.74       4.14 2014-02-27\n",
            "879     13.310   1022.44      0.58       2.78 2014-03-09\n",
            "880      5.930    994.27      0.75       7.24 2014-02-12\n",
            "881      7.640    988.63      0.69       9.96 2014-02-15\n",
            "\n",
            "[882 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# Create a new DataFrame with selected columns\n",
        "selected_columns = ['mean_temp', 'pressure', 'humidity', 'windSpeed', 'time']\n",
        "weather_selected = weather_daily_data[selected_columns]\n",
        "\n",
        "# Print the new dataset\n",
        "print(weather_selected)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miVCIR9kCr9I"
      },
      "source": [
        "## Combining the datasets with features and target column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pfr9Y-D5Q50",
        "outputId": "218ea360-986b-4bd7-f129-0d2234cc0ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in energy_daily_selected: Index(['LCLid', 'energy_sum', 'day'], dtype='object')\n",
            "Columns in weather_selected: Index(['mean_temp', 'pressure', 'humidity', 'windSpeed', 'time'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(\"Columns in energy_daily_selected:\", energy_daily_selected.columns)\n",
        "print(\"Columns in weather_selected:\", weather_selected.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL5IfAPrXj9h",
        "outputId": "b476100e-1513-4fd0-c997-15821f7d3a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     mean_temp  pressure  humidity  windSpeed       time  LCLid  energy_sum  \\\n",
            "0       10.405   1016.08      0.95       3.88 2011-11-11    NaN         NaN   \n",
            "1        5.535   1007.71      0.88       3.94 2011-12-11    NaN         NaN   \n",
            "2        9.180   1032.76      0.74       3.54 2011-12-27    NaN         NaN   \n",
            "3        5.315   1012.12      0.87       3.00 2011-12-02    NaN         NaN   \n",
            "4        5.695   1028.17      0.80       4.46 2011-12-24    NaN         NaN   \n",
            "..         ...       ...       ...        ...        ...    ...         ...   \n",
            "877      6.145   1002.10      0.79       4.55 2014-01-26    NaN         NaN   \n",
            "878      7.120   1007.02      0.74       4.14 2014-02-27    NaN         NaN   \n",
            "879     13.310   1022.44      0.58       2.78 2014-03-09    NaN         NaN   \n",
            "880      5.930    994.27      0.75       7.24 2014-02-12    NaN         NaN   \n",
            "881      7.640    988.63      0.69       9.96 2014-02-15    NaN         NaN   \n",
            "\n",
            "     day  \n",
            "0    NaN  \n",
            "1    NaN  \n",
            "2    NaN  \n",
            "3    NaN  \n",
            "4    NaN  \n",
            "..   ...  \n",
            "877  NaN  \n",
            "878  NaN  \n",
            "879  NaN  \n",
            "880  NaN  \n",
            "881  NaN  \n",
            "\n",
            "[882 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "# to combine the datasets, create a new dataset that will copy data from the household and then add the weather data.\n",
        "# After this, the data with non-matching dates between weather and household dataset will be considered missing values and removed\n",
        "\n",
        "# Create a new DataFrame using energy_daily_selected\n",
        "new_dataset = weather_selected.copy()\n",
        "\n",
        "# Add new columns with 'NA' values\n",
        "new_columns = ['LCLid','energy_sum','day']\n",
        "for column in new_columns:\n",
        "    new_dataset[column] = np.nan\n",
        "\n",
        "# Print the new dataset\n",
        "print(new_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piK8uri5fMCd",
        "outputId": "e430e118-03aa-4240-e26c-45c80d686e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     mean_temp  pressure  humidity  windSpeed       time  LCLid  energy_sum  \\\n",
            "0       10.405   1016.08      0.95       3.88 2011-11-11    NaN         NaN   \n",
            "1        5.535   1007.71      0.88       3.94 2011-12-11    NaN         NaN   \n",
            "2        9.180   1032.76      0.74       3.54 2011-12-27    NaN         NaN   \n",
            "3        5.315   1012.12      0.87       3.00 2011-12-02    NaN         NaN   \n",
            "4        5.695   1028.17      0.80       4.46 2011-12-24    NaN         NaN   \n",
            "..         ...       ...       ...        ...        ...    ...         ...   \n",
            "877      6.145   1002.10      0.79       4.55 2014-01-26    NaN         NaN   \n",
            "878      7.120   1007.02      0.74       4.14 2014-02-27    NaN         NaN   \n",
            "879     13.310   1022.44      0.58       2.78 2014-03-09    NaN         NaN   \n",
            "880      5.930    994.27      0.75       7.24 2014-02-12    NaN         NaN   \n",
            "881      7.640    988.63      0.69       9.96 2014-02-15    NaN         NaN   \n",
            "\n",
            "     day   date_only  \n",
            "0    NaN  2011-11-11  \n",
            "1    NaN  2011-12-11  \n",
            "2    NaN  2011-12-27  \n",
            "3    NaN  2011-12-02  \n",
            "4    NaN  2011-12-24  \n",
            "..   ...         ...  \n",
            "877  NaN  2014-01-26  \n",
            "878  NaN  2014-02-27  \n",
            "879  NaN  2014-03-09  \n",
            "880  NaN  2014-02-12  \n",
            "881  NaN  2014-02-15  \n",
            "\n",
            "[882 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Add a new column with only the date value\n",
        "new_dataset['date_only'] = new_dataset['time'].dt.date\n",
        "\n",
        "# Print the updated weather_selected DataFrame\n",
        "print(new_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFDaI7GdcpHp",
        "outputId": "ed6a7480-eacb-457b-a4b7-df57597a535d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "going into loop\n",
            "     mean_temp  pressure  humidity  windSpeed       time  LCLid  energy_sum  \\\n",
            "0       10.405   1016.08      0.95       3.88 2011-11-11    NaN         NaN   \n",
            "1        5.535   1007.71      0.88       3.94 2011-12-11    NaN         NaN   \n",
            "2        9.180   1032.76      0.74       3.54 2011-12-27    NaN         NaN   \n",
            "3        5.315   1012.12      0.87       3.00 2011-12-02    NaN         NaN   \n",
            "4        5.695   1028.17      0.80       4.46 2011-12-24    NaN         NaN   \n",
            "..         ...       ...       ...        ...        ...    ...         ...   \n",
            "877      6.145   1002.10      0.79       4.55 2014-01-26    NaN         NaN   \n",
            "878      7.120   1007.02      0.74       4.14 2014-02-27    NaN         NaN   \n",
            "879     13.310   1022.44      0.58       2.78 2014-03-09    NaN         NaN   \n",
            "880      5.930    994.27      0.75       7.24 2014-02-12    NaN         NaN   \n",
            "881      7.640    988.63      0.69       9.96 2014-02-15    NaN         NaN   \n",
            "\n",
            "     day   date_only  \n",
            "0    NaN  2011-11-11  \n",
            "1    NaN  2011-12-11  \n",
            "2    NaN  2011-12-27  \n",
            "3    NaN  2011-12-02  \n",
            "4    NaN  2011-12-24  \n",
            "..   ...         ...  \n",
            "877  NaN  2014-01-26  \n",
            "878  NaN  2014-02-27  \n",
            "879  NaN  2014-03-09  \n",
            "880  NaN  2014-02-12  \n",
            "881  NaN  2014-02-15  \n",
            "\n",
            "[882 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# # Iterate through rows in new_dataset\n",
        "# for index, row in new_dataset.iterrows():\n",
        "#     day = row['day']\n",
        "#     matching_weather = weather_selected[weather_selected['date_only'] == day]\n",
        "   # matching_weather = weather_selected[weather_selected['time'].dt.date == day]\n",
        "\n",
        "#     # If matching weather data is found, update columns in new_dataset\n",
        "#     if not matching_weather.empty:\n",
        "#         matching_weather_row = matching_weather.iloc[0]\n",
        "#         new_dataset.at[index, 'mean_temp'] = matching_weather_row['mean_temp']\n",
        "#         new_dataset.at[index, 'windSpeed'] = matching_weather_row['windSpeed']\n",
        "#         new_dataset.at[index, 'pressure'] = matching_weather_row['pressure']\n",
        "#         new_dataset.at[index, 'humidity'] = matching_weather_row['humidity']\n",
        "\n",
        "# # Print the updated new_dataset\n",
        "# print(new_dataset)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize a counter for the number of matches\n",
        "match_count = 0\n",
        "\n",
        "# Iterate through rows in new_dataset\n",
        "for index, row in new_dataset.iterrows():\n",
        "    if match_count >= 5:\n",
        "        break\n",
        "\n",
        "    day = row['day']\n",
        "    matching_energy_row = energy_daily_selected[energy_daily_selected['day'] == day]\n",
        "    print('going into loop')\n",
        "\n",
        "    # If matching energy data is found, display the date and update columns in new_dataset\n",
        "    if not matching_energy_row.empty:\n",
        "        match_count += 1\n",
        "        matching_date = matching_energy_row['day'].iloc[0]\n",
        "        print(f\"Matching date: {matching_date}\")\n",
        "\n",
        "        new_dataset.at[index, 'LCLid'] = matching_energy_row['LCLid'].iloc[0]\n",
        "        new_dataset.at[index, 'energy_sum'] = matching_energy_row['energy_sum'].iloc[0]\n",
        "        new_dataset.at[index, 'day'] = matching_energy_row['day'].iloc[0]\n",
        "\n",
        "# Print the updated new_dataset\n",
        "print(new_dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVelsQ53430r"
      },
      "source": [
        "# Splitting dataset to training and testing sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1208LqH1TPwF"
      },
      "source": [
        "Available datasets\n",
        "\n",
        "(for 500+ days)(household nos:5566 (in daily dataset))\n",
        "Daily bases\n",
        "Half-Hourly bases\n",
        "Each household has different amount of data(ie. some have more days of data)\n",
        "\n",
        "I need to create a code for taking in/loading all the data from the .csv files correctly.\n",
        "\n",
        "To show that i need to load one household data using an id.\n",
        "\n",
        "Then i need take 2(to begin with) random household id and club all the data in the id to do that i need to display them as well.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjDCXMXoizi1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "mount_file_id": "1oLHv4e-uSTEYGSiiJDsM6CuTErnsaA5X",
      "authorship_tag": "ABX9TyPW6bmjEf9g29xfeRnMmBlP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}